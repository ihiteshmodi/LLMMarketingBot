{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62015c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run 1-1 line in each cell if all dont work together.\n",
    "#pip install -qU pypdf\n",
    "#pip install sentence-transformers\n",
    "#pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad47c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary models\n",
    "from langchain.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e01697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up imp paths\n",
    "marketingdbfaiss_localstore__vectordbpath = r\"/Users/hitesh.modi/Desktop/Kinda Personal/LLM Marketing Bot/FAISS_marketingbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a5c6f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading our mistral model\n",
    "llm = Ollama(model=\"mistral\")\n",
    "debug_llm = Ollama(model=\"qwen2.5-coder:7b\")\n",
    "#print(llm(\"Test! are you working?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15e9f374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reason why your function is returning a coroutine object instead of the list of pages is because you're using an `async for` loop inside another `async for` loop. This means that each iteration of the outer loop will start a new coroutine, but it won't wait for it to finish before moving on to the next one.\n",
      "\n",
      "To fix this, you should use a regular `for` loop instead of an `async for` loop to iterate over the filepaths. You can then call `await loader.alazy_load()` inside the loop, which will wait for each PDF file to be fully loaded and appended to the `pages` list before moving on to the next one.\n",
      "\n",
      "Here's the corrected code:\n",
      "\n",
      "```python\n",
      "import asyncio\n",
      "\n",
      "async def read_pdfs_into_pages(filepaths):\n",
      "    pages = []\n",
      "    for filepath in filepaths:\n",
      "        loader = PyPDFLoader(filepath)\n",
      "        async for page in loader.alazy_load():\n",
      "            pages.append(page)\n",
      "    return pages\n",
      "```\n",
      "\n",
      "You can then call this function using `await`:\n",
      "\n",
      "```python\n",
      "filepaths = ['path/to/file1.pdf', 'path/to/file2.pdf']\n",
      "pages = await read_pdfs_into_pages(filepaths)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(debug_llm(\"\"\"\n",
    "                Can you debug this piece of python code for me?:\n",
    "                my original function was this\n",
    "                #Reading our pdf file via langchain\n",
    "loader = PyPDFLoader(filepaths[0])\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n",
    "    it returned a list object.mro\n",
    "    \n",
    "    \n",
    "    The function that you helped me with\n",
    "    async def read_pdfs_into_pages(filepaths):\n",
    "    pages = []\n",
    "    for filepath in filepaths:\n",
    "        loader = PyPDFLoader(filepath)\n",
    "        async for page in loader.alazy_load():\n",
    "            pages.append(page)\n",
    "    return pages\n",
    "    \n",
    "    returns a coroutine object\n",
    "                \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "510dddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = [\"/Users/hitesh.modi/Desktop/Kinda Personal/LLM Marketing Bot/pdf_files/Alex Hormozi 100 million leads.pdf\",\n",
    "             \"/Users/hitesh.modi/Desktop/Kinda Personal/LLM Marketing Bot/pdf_files/Alex Hormozi 100m Offers.pdf\",\n",
    "             \"/Users/hitesh.modi/Desktop/Kinda Personal/LLM Marketing Bot/pdf_files/DotCom Secrets Russel Brunson.pdf\",\n",
    "             \"/Users/hitesh.modi/Desktop/Kinda Personal/LLM Marketing Bot/pdf_files/Expert-Secrets-Russel Brunson.pdf\",\n",
    "             \"/Users/hitesh.modi/Desktop/Kinda Personal/LLM Marketing Bot/pdf_files/Russel Brunson Lead Funnels.pdf\",\n",
    "             \"/Users/hitesh.modi/Desktop/Kinda Personal/LLM Marketing Bot/pdf_files/Sabri Suby Sell like crazy.pdf\",\n",
    "             \"/Users/hitesh.modi/Desktop/Kinda Personal/LLM Marketing Bot/pdf_files/Traffic Secrets Russell Brunson.pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f86d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def read_pdfs_into_pages(filepaths):\n",
    "    pages = []\n",
    "    for filepath in filepaths:\n",
    "        loader = PyPDFLoader(filepath)\n",
    "        async for page in loader.alazy_load():\n",
    "            pages.append(page)\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e1181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pages(pages):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    docs = text_splitter.split_documents(pages)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6065183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_faiss_embeddings(docs):\n",
    "    #All have been splitted correctly, now time to load embeddings creator\n",
    "    embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    "    )   \n",
    "    embeddings = FAISS.from_documents(docs, embedding)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3db7c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers_from_FAISS_usingllm(FAISS_embeddings, query):\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=FAISS_embeddings.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "    return(qa_chain.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de9bb693",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_marketing_pdf_pages = await read_pdfs_into_pages(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c010f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metadata is : \")\n",
    "print(f\"{all_marketing_pdf_pages[1].metadata}\\n\")\n",
    "print(\" \")\n",
    "print(\"content is : \")\n",
    "print(all_marketing_pdf_pages[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9a1aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_marketing_pdf_split = split_pages(all_marketing_pdf_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19f57e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_marketing_pdf_split[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57570d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hv/3fk9wmx12gs74mp51cnpmhw80000gq/T/ipykernel_55629/2915709159.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(\n",
      "/Users/hitesh.modi/Desktop/Kinda Personal/LLM Marketing Bot/marketingvm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Requires internet\n",
    "all_marketing_embeddings = create_faiss_embeddings(all_marketing_pdf_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d41f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DB related operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7aedde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving FAISS vector DB\n",
    "all_marketing_embeddings.save_local(marketingdbfaiss_localstore__vectordbpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24dc872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading FAISS db from local\n",
    "\n",
    "\"\"\"\n",
    "allow_dangerous_deserialization=True\n",
    "this is just a warning, if the warning comes you can enable this as we ahve created our model locally!\n",
    "\"\"\"\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    "    ) \n",
    "all_marketing_embeddings = FAISS.load_local(folder_path=marketingdbfaiss_localstore__vectordbpath, embeddings=embedding,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393aeb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting to query our LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "604d31f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '\\nYou have information on what all books from the below mentioned authors?\\n1) Alex Hormozi\\n2) Russel Brunson\\n3) Sabri Suby\\n', 'result': \"1) Alex Hormozi - Traffic Secrets (as mentioned in the context)\\n  2) Russell Brunson is not explicitly mentioned in the provided context, but he has written books such as DotCom Secrets and Expert Secrets.\\n  3) Sabri Suby is also not explicitly mentioned in the provided context, so it's unclear if there are any books from this author within the given context.\", 'source_documents': [Document(page_content='ALEX HORMOZI', metadata={'source': '/Users/hitesh.modi/Desktop/Kinda Personal/LLM Marketing Bot/pdf_files/Alex Hormozi 100m Offers.pdf', 'page': 3}), Document(page_content='Figure\\t0.3:\\t\\nTraffic\\tSecrets\\n\\thelps\\tmarketers\\tlearn\\tthe\\tstrategies\\tto\\tdrive\\tconsistent\\ttraffic\\tto\\ttheir\\nfunnels.\\nEach\\tbook\\tin\\tthe\\tSecrets\\ttrilogy\\twas\\twritten\\tas\\ta\\tstand-alone\\tplaybook,\\tbut\\tmastering\\tthe\\nskills\\tfrom\\tall\\tthree\\tbooks\\tis\\tessential\\t\\nfor\\tthe\\tlong-term\\tgrowth\\tof\\tyour\\tcompany.\\tBecause\\tof\\nthat,\\teach\\tbook\\trefers\\tto\\tand\\tties\\tin\\timportant\\tconcepts\\tfrom\\tthe\\tothers.\\nIf\\tyou\\tare\\tinterested\\tin\\tthe\\tmost\\tup-to-date\\tinformation,\\tI\\tinvite\\tyou\\tto\\tgo\\tto\\t\\nMarketingSecre\\nts.com\\n\\tto\\tlisten\\tin\\ton\\tmy\\tpodcast,\\t\\nMarketing\\tSecrets\\n.\\tIt’s\\tpublished\\ttwice\\ta\\tweek\\tand\\tcovers\\neverything\\twe’re\\tlearning\\tand\\tdiscovering\\tin\\treal\\ttime.\\tI\\tshare\\tnew\\tsecrets\\tevery\\tweek\\tfor\\nfree\\tthat\\tbuild\\ton\\tthe\\tevergreen\\ttopics\\tand\\tframeworks\\tthat\\tyou’re\\tmastering\\tin\\tthese\\tbooks.\\nI\\thope\\tthat\\tyou\\tcan\\tuse\\tthis\\ttrilogy\\tof\\tbooks\\tto\\tchange\\tthe\\tlives\\tof\\tthe\\tcustomers\\tyou\\thave\\nbeen\\tcalled\\tto\\tserve.\\tEverything\\twritten\\tin\\tthese\\tthree\\tbooks\\tis\\tevergreen\\tand\\tfocuses\\ton\\nconcepts\\tthat\\thave\\tworked\\tyesterday,\\tare\\tworking\\ttoday,\\tand\\twill\\tcontinue\\tto\\twork\\ttomorrow\\nand\\tforever.', metadata={'source': '/Users/hitesh.modi/Desktop/Kinda Personal/LLM Marketing Bot/pdf_files/Traffic Secrets Russell Brunson.pdf', 'page': 14}), Document(page_content='professionals,\\tdirect\\tmarketing\\tpros,\\tand\\tCEOs.\\tHe\\tis\\talso\\tthe\\tauthor\\tof\\tover\\t20\\tbooks,\\nincluding\\t\\nNo\\tB.S.\\tGuide\\tto\\tRuthless\\tManagement\\tof\\tPeople\\tand\\tProfits\\n\\t(2nd\\tEdition).\\nInformation\\tabout\\tDan\\tat:\\t\\nwww.NoBSBooks.com\\n\\tand\\t\\nwww.GKIC.com\\n.', metadata={'source': '/Users/hitesh.modi/Desktop/Kinda Personal/LLM Marketing Bot/pdf_files/DotCom Secrets Russel Brunson.pdf', 'page': 15})]}\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "You have information on what all books from the below mentioned authors?\n",
    "1) Alex Hormozi\n",
    "2) Russel Brunson\n",
    "3) Sabri Suby\n",
    "\"\"\"\n",
    "response = get_answers_from_FAISS_usingllm(all_marketing_embeddings, question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aab0e8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '\\nYou have information on what all books from the below mentioned authors?\\n1) Alex Hormozi\\n2) Russel Brunson\\n3) Sabri Suby\\n',\n",
       " 'result': \"1) Alex Hormozi - Traffic Secrets (as mentioned in the context)\\n  2) Russell Brunson is not explicitly mentioned in the provided context, but he has written books such as DotCom Secrets and Expert Secrets.\\n  3) Sabri Suby is also not explicitly mentioned in the provided context, so it's unclear if there are any books from this author within the given context.\",\n",
       " 'source_documents': [Document(page_content='ALEX HORMOZI', metadata={'source': '/Users/hitesh.modi/Desktop/Kinda Personal/LLM Marketing Bot/pdf_files/Alex Hormozi 100m Offers.pdf', 'page': 3}),\n",
       "  Document(page_content='Figure\\t0.3:\\t\\nTraffic\\tSecrets\\n\\thelps\\tmarketers\\tlearn\\tthe\\tstrategies\\tto\\tdrive\\tconsistent\\ttraffic\\tto\\ttheir\\nfunnels.\\nEach\\tbook\\tin\\tthe\\tSecrets\\ttrilogy\\twas\\twritten\\tas\\ta\\tstand-alone\\tplaybook,\\tbut\\tmastering\\tthe\\nskills\\tfrom\\tall\\tthree\\tbooks\\tis\\tessential\\t\\nfor\\tthe\\tlong-term\\tgrowth\\tof\\tyour\\tcompany.\\tBecause\\tof\\nthat,\\teach\\tbook\\trefers\\tto\\tand\\tties\\tin\\timportant\\tconcepts\\tfrom\\tthe\\tothers.\\nIf\\tyou\\tare\\tinterested\\tin\\tthe\\tmost\\tup-to-date\\tinformation,\\tI\\tinvite\\tyou\\tto\\tgo\\tto\\t\\nMarketingSecre\\nts.com\\n\\tto\\tlisten\\tin\\ton\\tmy\\tpodcast,\\t\\nMarketing\\tSecrets\\n.\\tIt’s\\tpublished\\ttwice\\ta\\tweek\\tand\\tcovers\\neverything\\twe’re\\tlearning\\tand\\tdiscovering\\tin\\treal\\ttime.\\tI\\tshare\\tnew\\tsecrets\\tevery\\tweek\\tfor\\nfree\\tthat\\tbuild\\ton\\tthe\\tevergreen\\ttopics\\tand\\tframeworks\\tthat\\tyou’re\\tmastering\\tin\\tthese\\tbooks.\\nI\\thope\\tthat\\tyou\\tcan\\tuse\\tthis\\ttrilogy\\tof\\tbooks\\tto\\tchange\\tthe\\tlives\\tof\\tthe\\tcustomers\\tyou\\thave\\nbeen\\tcalled\\tto\\tserve.\\tEverything\\twritten\\tin\\tthese\\tthree\\tbooks\\tis\\tevergreen\\tand\\tfocuses\\ton\\nconcepts\\tthat\\thave\\tworked\\tyesterday,\\tare\\tworking\\ttoday,\\tand\\twill\\tcontinue\\tto\\twork\\ttomorrow\\nand\\tforever.', metadata={'source': '/Users/hitesh.modi/Desktop/Kinda Personal/LLM Marketing Bot/pdf_files/Traffic Secrets Russell Brunson.pdf', 'page': 14}),\n",
       "  Document(page_content='professionals,\\tdirect\\tmarketing\\tpros,\\tand\\tCEOs.\\tHe\\tis\\talso\\tthe\\tauthor\\tof\\tover\\t20\\tbooks,\\nincluding\\t\\nNo\\tB.S.\\tGuide\\tto\\tRuthless\\tManagement\\tof\\tPeople\\tand\\tProfits\\n\\t(2nd\\tEdition).\\nInformation\\tabout\\tDan\\tat:\\t\\nwww.NoBSBooks.com\\n\\tand\\t\\nwww.GKIC.com\\n.', metadata={'source': '/Users/hitesh.modi/Desktop/Kinda Personal/LLM Marketing Bot/pdf_files/DotCom Secrets Russel Brunson.pdf', 'page': 15})]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb4337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472f1ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marketingvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
